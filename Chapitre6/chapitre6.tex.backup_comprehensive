\chapter{Service IA and dashboard}\label{chap6}

\lhead{Chapitre VI: Services IA}
\dominitoc
\rhead{\thepage}
\minitoc

\section{Introduction}
Ce sixième et dernier chapitre présente de manière exhaustive l'architecture technique complète des services d'intelligence artificielle développés pour le système d'optimisation de la planification de production. Ce chapitre détaille de manière systématique les spécifications techniques des interfaces de programmation (APIs), l'architecture et les fonctionnalités de l'interface utilisateur, l'intégration opérationnelle des modèles de machine learning en environnement de production, ainsi que la documentation technique complète du système.

L'approche architecturale adoptée suit rigoureusement les principes fondamentaux de l'architecture microservices, garantissant ainsi la scalabilité horizontale, la maintenabilité à long terme et la robustesse opérationnelle du système. Les services sont conçus selon les principes de responsabilité unique et de faible couplage, les rendant indépendants, facilement testables et déployables de manière isolée.

\section{Architecture des Services IA}

\subsection{Vue d'ensemble de l'architecture}
Le système d'intelligence artificielle est structuré en plusieurs services spécialisés, chacun ayant une responsabilité spécifique dans le processus d'optimisation de la planification.

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=2cm, auto]
    % Services
    \node[service] (frontend) {Interface Utilisateur\\React Dashboard};
    \node[service, below of=frontend] (api) {API Gateway\\FastAPI};
    \node[service, below left of=api, xshift=-2cm] (predict) {Service Prédiction\\Time Predictor};
    \node[service, below right of=api, xshift=2cm] (schedule) {Service Ordonnancement\\Scheduler};
    \node[service, below of=api, yshift=-1cm] (analytics) {Service Analytics\\KPIs \& Reports};
    \node[service, below left of=analytics, xshift=-1cm] (mlflow) {MLflow\\Model Registry};
    \node[service, below right of=analytics, xshift=1cm] (db) {Base de Données\\PostgreSQL};

    % Connexions
    \draw[arrow] (frontend) -- (api);
    \draw[arrow] (api) -- (predict);
    \draw[arrow] (api) -- (schedule);
    \draw[arrow] (api) -- (analytics);
    \draw[arrow] (predict) -- (mlflow);
    \draw[arrow] (schedule) -- (mlflow);
    \draw[arrow] (analytics) -- (db);
    \draw[arrow] (predict) -- (db);
    \draw[arrow] (schedule) -- (db);
\end{tikzpicture}
\caption{Architecture des services IA}
\label{fig:ia_architecture}
\end{figure}

\subsection{Composants principaux}

\subsubsection{Service de Prédiction}
Le service de prédiction est responsable de l'estimation des temps de production pour chaque ordre de fabrication. Il utilise des modèles de machine learning entraînés (XGBoost, Random Forest) pour prédire avec précision la durée nécessaire pour chaque opération.

\textbf{Fonctionnalités principales :}
\begin{itemize}
    \item Prédiction de temps pour un ordre unique
    \item Prédiction en lot pour plusieurs ordres
    \item Validation des données d'entrée
    \item Gestion des modèles ML (chargement, mise à jour)
    \item Métriques de performance en temps réel
\end{itemize}

\subsubsection{Service d'Ordonnancement}
Le service d'ordonnancement optimise la planification des ordres de fabrication en utilisant la programmation par contraintes (CP-SAT). Il prend en compte les contraintes de ressources, les délais et les priorités pour générer des plannings optimaux.

\textbf{Fonctionnalités principales :}
\begin{itemize}
    \item Optimisation de la planification
    \item Analyse des goulots d'étranglement
    \item Gestion des contraintes de ressources
    \item Simulation de scénarios what-if
    \item Génération de rapports d'ordonnancement
\end{itemize}

\subsubsection{Service Analytics}
Le service analytics calcule les indicateurs de performance clés (KPIs), génère des rapports et fournit des analyses de tendances pour le suivi des performances de production.

\textbf{Fonctionnalités principales :}
\begin{itemize}
    \item Calcul des KPIs en temps réel
    \item Analyse des tendances temporelles
    \item Génération de rapports personnalisés
    \item Tableaux de bord interactifs
    \item Alertes de performance
\end{itemize}

\section{Spécifications des APIs}

\subsection{API de Prédiction}

\subsubsection{Endpoint de prédiction simple}
\begin{verbatim}
POST /api/v1/predict/time
Content-Type: application/json
Authorization: Bearer <token>

{
    "nbr_plies": 10,
    "longeur_trace": 1000.0,
    "longeur_matelas": 1100.0,
    "largeur": 150.0,
    "machine": "Machine_A"
}
\end{verbatim}

\textbf{Réponse :}
\begin{verbatim}
{
    "predicted_time_minutes": 65.4,
    "confidence_score": 0.92,
    "model_version": "1.0.0",
    "prediction_timestamp": "2024-01-01T12:00:00Z",
    "features_used": [
        "Nbr Plies",
        "Longeur Tracé", 
        "Longeur Matela",
        "Largeur",
        "Machine"
    ]
}
\end{verbatim}

\subsubsection{Endpoint de prédiction en lot}
\begin{verbatim}
POST /api/v1/predict/batch
Content-Type: application/json
Authorization: Bearer <token>

{
    "orders": [
        {
            "order_id": "ORD_001",
            "nbr_plies": 10,
            "longeur_trace": 1000.0,
            "longeur_matelas": 1100.0,
            "largeur": 150.0,
            "machine": "Machine_A"
        },
        {
            "order_id": "ORD_002", 
            "nbr_plies": 15,
            "longeur_trace": 1200.0,
            "longeur_matelas": 1300.0,
            "largeur": 160.0,
            "machine": "Machine_B"
        }
    ]
}
\end{verbatim}

\subsection{API d'Ordonnancement}

\subsubsection{Endpoint d'optimisation de planification}
\begin{verbatim}
POST /api/v1/schedule/optimize
Content-Type: application/json
Authorization: Bearer <token>

{
    "orders": [
        {
            "order_id": "ORD_001",
            "nbr_plies": 10,
            "longeur_trace": 1000.0,
            "longeur_matelas": 1100.0,
            "largeur": 150.0,
            "machine": "Machine_A",
            "operator": "OP_1",
            "priority": 1,
            "due_date": "2024-01-02T18:00:00Z",
            "estimated_time": 65
        }
    ],
    "machines": ["Machine_A", "Machine_B", "Machine_C"],
    "operators": ["OP_1", "OP_2", "OP_3"],
    "start_date": "2024-01-01T08:00:00Z",
    "horizon_days": 7,
    "optimization_objective": "makespan"
}
\end{verbatim}

\textbf{Réponse :}
\begin{verbatim}
{
    "optimization_status": "optimal",
    "total_makespan": 480,
    "utilization_rate": 0.85,
    "schedule": [
        {
            "task_id": "ORD_001",
            "start_time": "2024-01-01T08:00:00Z",
            "end_time": "2024-01-01T09:05:00Z",
            "duration_minutes": 65,
            "machine": "Machine_A",
            "operator": "OP_1"
        }
    ],
    "constraints_satisfied": true,
    "optimization_time_seconds": 2.3
}
\end{verbatim}

\subsection{API Analytics}

\subsubsection{Endpoint de calcul des KPIs}
\begin{verbatim}
POST /api/v1/analytics/kpis
Content-Type: application/json
Authorization: Bearer <token>

{
    "start_date": "2024-01-01T00:00:00Z",
    "end_date": "2024-01-31T23:59:59Z",
    "include_trends": true,
    "metrics": [
        "production_efficiency",
        "on_time_delivery_rate",
        "average_completion_time",
        "machine_utilization"
    ]
}
\end{verbatim}

\textbf{Réponse :}
\begin{verbatim}
{
    "production_efficiency": 87.5,
    "on_time_delivery_rate": 94.2,
    "average_completion_time": 58.3,
    "total_orders": 165,
    "machine_utilization": {
        "Machine_A": 85.2,
        "Machine_B": 78.9,
        "Machine_C": 82.1
    },
    "operator_utilization": {
        "OP_1": 80.5,
        "OP_2": 75.2,
        "OP_3": 88.1
    },
    "quality_metrics": {
        "defect_rate": 0.02,
        "rework_rate": 0.05,
        "customer_satisfaction": 0.92
    },
    "trends": {
        "production_efficiency_trend": "increasing",
        "completion_time_trend": "decreasing"
    }
}
\end{verbatim}

\section{Interface Utilisateur}

\subsection{Architecture du Dashboard React}

Le dashboard utilisateur est développé avec React 18 et utilise une architecture moderne basée sur les hooks et les composants fonctionnels.

\subsubsection{Structure des composants}
\begin{verbatim}
src/
├── components/
│   └── Layout.js          # Layout principal avec navigation
├── pages/
│   ├── Dashboard.js       # Tableau de bord principal
│   ├── Planning.js        # Interface de planification
│   ├── Analytics.js       # Analytics et KPIs
│   ├── WhatIf.js          # Simulateur what-if
│   ├── Settings.js        # Paramètres système
│   └── NotFound.js        # Page 404
├── services/
│   └── api.js             # Service API client
├── styles/
│   └── index.css          # Styles Tailwind CSS
├── App.js                 # Composant principal
└── index.js               # Point d'entrée
\end{verbatim}

\subsubsection{Gestion d'état}
Le dashboard utilise React Query pour la gestion de l'état serveur et React Hook Form pour la gestion des formulaires.

\textbf{Configuration React Query :}
\begin{verbatim}
const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      retry: 1,
      refetchOnWindowFocus: false,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});
\end{verbatim}

\subsection{Pages principales}

\subsubsection{Dashboard Principal}
Le dashboard principal fournit une vue d'ensemble des performances de production en temps réel.

\textbf{Composants clés :}
\begin{itemize}
    \item \textbf{MetricCards} : Affichage des KPIs principaux
    \item \textbf{ProductionTrend} : Graphique de tendance de production
    \item \textbf{MachineUtilization} : Utilisation des machines
    \item \textbf{QualityDistribution} : Distribution de la qualité
    \item \textbf{RecentActivity} : Flux d'activité récente
\end{itemize}

\textbf{Exemple d'utilisation :}
\begin{verbatim}
const Dashboard = () => {
  const { data: dashboardData, isLoading, error } = useQuery(
    'dashboard',
    () => apiService.getDashboardData(),
    {
      refetchInterval: 30000, // Refetch every 30 seconds
    }
  );

  if (isLoading) {
    return <LoadingSpinner />;
  }

  return (
    <div className="space-y-6">
      <MetricCards metrics={dashboardData.summary_metrics} />
      <ProductionTrendChart data={dashboardData.charts_data} />
      <MachineUtilizationChart data={dashboardData.machine_utilization} />
    </div>
  );
};
\end{verbatim}

\subsubsection{Page de Planification}
La page de planification permet la gestion des ordres et l'optimisation des plannings.

\textbf{Fonctionnalités :}
\begin{itemize}
    \item Création d'ordres de fabrication
    \item Sélection et gestion des ordres
    \item Optimisation de la planification
    \item Visualisation des résultats
    \item Gestion des ressources
\end{itemize}

\textbf{Formulaires de création d'ordre :}
\begin{verbatim}
const OrderForm = () => {
  const { register, handleSubmit, formState: { errors } } = useForm();
  
  const onSubmit = (data) => {
    createOrderMutation.mutate(data);
  };

  return (
    <form onSubmit={handleSubmit(onSubmit)} className="space-y-4">
      <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-4">
        <div>
          <label className="form-label">Number of Plies</label>
          <input
            type="number"
            {...register('nbr_plies', { 
              required: 'Number of plies is required', 
              min: 1, 
              max: 50 
            })}
            className="form-input"
            placeholder="10"
          />
          {errors.nbr_plies && (
            <p className="form-error">{errors.nbr_plies.message}</p>
          )}
        </div>
        {/* Autres champs... */}
      </div>
    </form>
  );
};
\end{verbatim}

\subsubsection{Page Analytics}
La page analytics fournit des analyses approfondies des performances et des tendances.

\textbf{Composants d'analyse :}
\begin{itemize}
    \item \textbf{KPICalculator} : Calcul des indicateurs de performance
    \item \textbf{TrendAnalyzer} : Analyse des tendances temporelles
    \item \textbf{ResourceUtilization} : Utilisation des ressources
    \item \textbf{PerformanceComparison} : Comparaison de performances
    \item \textbf{ReportGenerator} : Générateur de rapports
\end{itemize}

\subsubsection{Simulateur What-If}
Le simulateur what-if permet de tester différents scénarios et d'analyser leur impact.

\textbf{Types de scénarios :}
\begin{itemize}
    \item Ajout de nouvelles machines
    \item Ajout de nouveaux opérateurs
    \item Augmentation du volume de commandes
    \item Amélioration de l'efficacité
    \item Réduction des temps de traitement
\end{itemize}

\textbf{Configuration de scénario :}
\begin{verbatim}
const ScenarioConfig = ({ selectedScenario }) => {
  const { register, handleSubmit } = useForm();
  
  const scenarioTypes = [
    {
      id: 'add_machine',
      name: 'Add New Machine',
      description: 'Simulate adding new machines to increase capacity',
      icon: Settings,
      color: 'primary'
    },
    // Autres types de scénarios...
  ];

  return (
    <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
      {scenarioTypes.map((scenario) => (
        <button
          key={scenario.id}
          onClick={() => setSelectedScenario(scenario.id)}
          className={`p-4 rounded-lg border-2 transition-all duration-200 ${
            selectedScenario === scenario.id
              ? 'border-primary-500 bg-primary-50'
              : 'border-gray-200 hover:border-gray-300'
          }`}
        >
          <div className="flex items-center space-x-3">
            <scenario.icon className="h-6 w-6" />
            <div className="text-left">
              <h4 className="font-medium text-gray-900">
                {scenario.name}
              </h4>
              <p className="text-sm text-gray-500">
                {scenario.description}
              </p>
            </div>
          </div>
        </button>
      ))}
    </div>
  );
};
\end{verbatim}

\section{Intégration des Modèles ML}

\subsection{Service de Prédiction}

\subsubsection{Chargement des modèles}
Les modèles de machine learning sont chargés au démarrage de l'application et mis en cache pour des performances optimales.

\begin{verbatim}
class TimePredictor:
    def __init__(self, model_type='xgboost', random_state=42):
        self.model_type = model_type
        self.random_state = random_state
        self.model = None
        self.preprocessor = None
        self.feature_names = None
        self.target_col = 'TEMPS DISP'

    def load_model(self, path):
        """Charge un modèle pré-entraîné depuis le disque"""
        if not os.path.exists(path):
            raise FileNotFoundError(f"Model file not found at {path}")
        self.pipeline = joblib.load(path)
        self.preprocessor = self.pipeline.named_steps['preprocessor']
        self.model = self.pipeline.named_steps['regressor']
        print(f"Model loaded from {path}")
\end{verbatim}

\subsubsection{Préprocessing des données}
Le service de prédiction inclut un pipeline de préprocessing robuste pour gérer les données d'entrée.

\begin{verbatim}
def preprocess_data(self, data):
    """Préprocesse les données d'entrée pour la prédiction"""
    df = data.copy()
    
    # Conversion des colonnes numériques
    for col in ['Nbr Plies', 'Longeur Tracé', 'Longeur Matela', 'Largeur']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # Feature Engineering
    if 'Longeur Matela' in df.columns and 'Largeur' in df.columns:
        df['Surface_Matelas'] = df['Longeur Matela'] * df['Largeur']
    if 'Nbr Plies' in df.columns and 'Surface_Matelas' in df.columns:
        df['Volume_Matelas'] = df['Nbr Plies'] * df['Surface_Matelas']
    
    # Encodage des variables catégorielles
    if 'Machine' in df.columns:
        df['Machine'] = df['Machine'].astype(str)
    
    return df, features
\end{verbatim}

\subsection{Service d'Ordonnancement}

\subsubsection{Modélisation des contraintes}
Le service d'ordonnancement utilise la programmation par contraintes pour modéliser le problème de planification.

\begin{verbatim}
class ProductionScheduler:
    def __init__(self, machines, operators, start_date=None):
        self.machines = machines
        self.operators = operators
        self.model = cp_model.CpModel()
        self.solver = cp_model.CpSolver()
        self.horizon = 30  # days
        self.start_date = start_date if start_date else datetime.now().date()
        self.intervals = {}

    def add_task(self, task_id, machine_id, operator_id, 
                 predicted_duration_minutes, due_date=None):
        """Ajoute une t'che au planificateur"""
        duration = int(predicted_duration_minutes)
        
        # Variables de temps
        start_var = self.model.NewIntVar(0, self.horizon * 24 * 60, f'start_{task_id}')
        end_var = self.model.NewIntVar(0, self.horizon * 24 * 60, f'end_{task_id}')
        
        # Variable d'intervalle
        interval_var = self.model.NewIntervalVar(
            start_var, duration, end_var, f'interval_{task_id}'
        )
        self.intervals[task_id] = interval_var
        
        # Contrainte de délai
        if due_date:
            due_date_minutes = (due_date - self.start_date).days * 24 * 60
            self.model.Add(end_var <= due_date_minutes)
        
        return start_var, end_var, interval_var
\end{verbatim}

\section{Sécurité et Authentification}

\subsection{Système d'authentification}
Le système utilise JWT (JSON Web Tokens) pour l'authentification et l'autorisation des utilisateurs.

\subsubsection{Génération des tokens}
\begin{verbatim}
def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    """Crée un token JWT d'accès"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt
\end{verbatim}

\subsubsection{Vérification des tokens}
\begin{verbatim}
def decode_access_token(token: str):
    """Décode et vérifie un token JWT"""
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise APIException("Invalid token", 401)
        return username
    except JWTError:
        raise APIException("Invalid token", 401)
\end{verbatim}

\subsection{Contrôle d'accès basé sur les rôles (RBAC)}
Le système implémente un contrôle d'accès basé sur les rôles pour gérer les permissions des utilisateurs.

\textbf{Rôles définis :}
\begin{itemize}
    \item \textbf{Admin} : Accès complet à tous les endpoints
    \item \textbf{Manager} : Accès aux analytics et à la planification
    \item \textbf{Operator} : Accès limité aux prédictions et au planning
    \item \textbf{Viewer} : Accès en lecture seule aux analytics
\end{itemize}

\section{Monitoring et Observabilité}

\subsection{Métriques de performance}
Le système collecte des métriques détaillées sur les performances des modèles et des services.

\subsubsection{Métriques des modèles}
\begin{itemize}
    \item Précision des prédictions (MAE, RMSE, R²)
    \item Temps de réponse des prédictions
    \item Utilisation des ressources (CPU, mémoire)
    \item Fréquence des requêtes
    \item Taux d'erreur
\end{itemize}

\subsubsection{Métriques des services}
\begin{itemize}
    \item Disponibilité des services (uptime)
    \item Temps de réponse des APIs
    \item Débit des requêtes
    \item Utilisation des ressources système
    \item Logs d'erreurs et d'exceptions
\end{itemize}

\subsection{Alertes et notifications}
Le système génère des alertes automatiques pour les événements critiques.

\textbf{Types d'alertes :}
\begin{itemize}
    \item Dérive de modèle (model drift)
    \item Performance dégradée des services
    \item Erreurs de prédiction élevées
    \item Surcharge des ressources
    \item Échecs d'ordonnancement
\end{itemize}

\section{Documentation Technique}

\subsection{Documentation API}
La documentation API est générée automatiquement à partir des annotations FastAPI et est accessible via Swagger UI.

\textbf{Endpoints de documentation :}
\begin{itemize}
    \item \texttt{/docs} : Interface Swagger UI
    \item \texttt{/openapi.json} : Spécification OpenAPI
    \item \texttt{/redoc} : Documentation ReDoc
\end{itemize}

\subsection{Guide de déploiement}
Le système est conçu pour être déployé dans des environnements conteneurisés avec Docker.

\subsubsection{Configuration Docker}
\begin{verbatim}
# Dockerfile pour l'API
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
\end{verbatim}

\subsubsection{Docker Compose}
\begin{verbatim}
version: '3.8'
services:
  api:
    build: ./api
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/production_db
    depends_on:
      - db
      - mlflow

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:8000

  db:
    image: postgres:13
    environment:
      - POSTGRES_DB=production_db
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data

  mlflow:
    image: mlflow/mlflow
    ports:
      - "5000:5000"
    volumes:
      - mlflow_data:/mlflow
\end{verbatim}

\subsection{Tests et validation}
Le système inclut une suite de tests complète pour garantir la qualité et la fiabilité.

\subsubsection{Tests unitaires}
\begin{verbatim}
def test_time_prediction():
    """Test de prédiction de temps"""
    predictor = TimePredictor(model_type='xgboost')
    test_data = {
        'nbr_plies': 10,
        'longeur_trace': 1000.0,
        'longeur_matelas': 1100.0,
        'largeur': 150.0,
        'machine': 'Machine_A'
    }
    
    prediction = predictor.predict(test_data)
    assert prediction > 0
    assert isinstance(prediction, float)
\end{verbatim}

\subsubsection{Tests d'intégration}
\begin{verbatim}
def test_schedule_optimization():
    """Test d'optimisation de planification"""
    scheduler = ProductionScheduler(['M1', 'M2'], ['OP1', 'OP2'])
    
    # Ajouter des t'ches
    scheduler.add_task('T1', 'M1', 'OP1', 60)
    scheduler.add_task('T2', 'M2', 'OP2', 90)
    
    # Optimiser
    result = scheduler.solve()
    
    assert result is not None
    assert len(result) == 2
    assert result['T1']['machine'] == 'M1'
    assert result['T2']['machine'] == 'M2'
\end{verbatim}

\section{Performance et Optimisation}

\subsection{Optimisations des modèles}
Les modèles de machine learning sont optimisés pour des performances maximales en production.

\subsubsection{Cache des prédictions}
Les prédictions fréquemment demandées sont mises en cache pour réduire la latence.

\begin{verbatim}
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_prediction(nbr_plies, longeur_trace, longeur_matelas, largeur, machine):
    """Prédiction mise en cache pour les paramètres fréquents"""
    return predictor.predict({
        'nbr_plies': nbr_plies,
        'longeur_trace': longeur_trace,
        'longeur_matelas': longeur_matelas,
        'largeur': largeur,
        'machine': machine
    })
\end{verbatim}

\subsubsection{Prédiction en lot}
Les prédictions en lot sont optimisées pour traiter plusieurs ordres simultanément.

\begin{verbatim}
def batch_predict(orders):
    """Prédiction optimisée en lot"""
    # Préparation des données en lot
    batch_data = pd.DataFrame(orders)
    
    # Prédiction vectorisée
    predictions = model.predict(batch_data)
    
    # Formatage des résultats
    results = []
    for i, order in enumerate(orders):
        results.append({
            'order_id': order['order_id'],
            'predicted_time_minutes': predictions[i],
            'confidence_score': calculate_confidence(predictions[i])
        })
    
    return results
\end{verbatim}

\subsection{Optimisations de l'ordonnancement}
L'algorithme d'ordonnancement est optimisé pour traiter efficacement de grands volumes de t'ches.

\subsubsection{Parallélisation}
Les calculs d'ordonnancement sont parallélisés pour améliorer les performances.

\begin{verbatim}
from concurrent.futures import ThreadPoolExecutor

def parallel_schedule_optimization(orders, machines, operators):
    """Optimisation parallèle de la planification"""
    # Division des ordres en groupes
    order_groups = split_orders_into_groups(orders, len(machines))
    
    # Optimisation parallèle de chaque groupe
    with ThreadPoolExecutor(max_workers=len(machines)) as executor:
        futures = []
        for i, group in enumerate(order_groups):
            future = executor.submit(
                optimize_group, 
                group, 
                machines[i], 
                operators[i]
            )
            futures.append(future)
        
        # Collecte des résultats
        results = []
        for future in futures:
            results.extend(future.result())
    
    return merge_schedule_results(results)
\end{verbatim}

\section{Évolutivité et Maintenance}

\subsection{Architecture évolutive}
Le système est conçu pour être facilement extensible et maintenable.

\subsubsection{Microservices}
Chaque service est indépendant et peut être développé, testé et déployé séparément.

\subsubsection{API Gateway}
L'API Gateway centralise la gestion des requêtes et fournit des fonctionnalités transversales.

\subsection{Maintenance des modèles}
Les modèles de machine learning sont régulièrement mis à jour et réentraînés.

\subsubsection{Monitoring de la dérive}
Le système surveille automatiquement la dérive des modèles et déclenche des alertes.

\begin{verbatim}
def monitor_model_drift():
    """Surveille la dérive du modèle"""
    current_performance = evaluate_model_performance()
    baseline_performance = get_baseline_performance()
    
    drift_score = calculate_drift_score(current_performance, baseline_performance)
    
    if drift_score > DRIFT_THRESHOLD:
        send_alert("Model drift detected", drift_score)
        trigger_model_retraining()
\end{verbatim}

\subsubsection{Réentraînement automatique}
Le système peut automatiquement réentraîner les modèles avec de nouvelles données.

\begin{verbatim}
def auto_retrain_model():
    """Réentraînement automatique du modèle"""
    # Collecte des nouvelles données
    new_data = collect_recent_data()
    
    # Validation des données
    if validate_data_quality(new_data):
        # Réentraînement
        new_model = train_model(new_data)
        
        # Validation du nouveau modèle
        if validate_model_performance(new_model):
            # Déploiement du nouveau modèle
            deploy_model(new_model)
            log_model_update()
\end{verbatim}

\section{Conclusion}
Ce chapitre a présenté l'architecture complète des services d'intelligence artificielle développés pour le système d'optimisation de la planification de production. Les spécifications techniques détaillées, l'interface utilisateur moderne, et l'intégration robuste des modèles de machine learning constituent une solution complète et évolutive.

L'approche microservices adoptée garantit la scalabilité et la maintenabilité du système, tandis que les fonctionnalités avancées comme le monitoring, les alertes et le réentraînement automatique assurent la fiabilité et la performance continue de la solution.

Le système est prêt pour le déploiement en production et peut être facilement étendu pour répondre aux besoins futurs de l'entreprise.
