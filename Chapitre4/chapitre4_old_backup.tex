\chapter{Modeling, Evaluation, Deployment (MLOps)}\label{chap4:modeling}

\lhead{Chapitre IV: Modélisation et Algorithmes ML}
\dominitoc 
\rhead{\thepage}
\minitoc

\section{Introduction}\label{chap4:intro}

Ce quatrième chapitre présente de manière exhaustive la phase de modélisation du projet CRISP-ML(Q), correspondant aux phases 4 (\textit{Modeling}) et 5 (\textit{Evaluation}) de la méthodologie structurée de développement de systèmes d'intelligence artificielle \cite{studer2021towards}. Ce chapitre expose le développement de deux modèles complémentaires et interdépendants : un modèle de prédiction du temps de matelassage basé sur l'apprentissage automatique, et un algorithme d'optimisation de la planification fondé sur la programmation par contraintes. Ces modèles constituent le cœur algorithmique et décisionnel de notre système d'intelligence artificielle pour l'optimisation de la planification de l'atelier de coupe textile.

L'approche méthodologique adoptée combine de manière synergique des techniques avancées de machine learning supervisé pour la prédiction des temps de production \cite{hastie2009elements} avec des algorithmes d'optimisation combinatoire pour la planification opérationnelle \cite{pinedo2016scheduling}, garantissant simultanément une précision élevée des estimations temporelles et une efficacité optimale de l'ordonnancement des ressources.

\section{Phase 4 : Modélisation (Modeling)}\label{chap4:modeling_phase}

\subsection{Sélection des techniques de modélisation}

\subsubsection{Modèle de prédiction du temps}

Pour la prédiction du temps de matelassage, nous comparons plusieurs algorithmes de régression :

\begin{table}[H]
\centering
\caption{Comparaison des algorithmes de régression}
\begin{tabular}{|p{3cm}|p{2cm}|p{3cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Algorithme} & \textbf{Complexité} & \textbf{Interprétabilité} & \textbf{Robustesse} & \textbf{Performance attendue} \\
\hline
Régression Linéaire & Faible & Élevée & Faible & R² $\approx$ 0.45 \\
\hline
Random Forest & Moyenne & Moyenne & Élevée & R² $\approx$ 0.75 \\
\hline
XGBoost & Élevée & Faible & Élevée & R² $\approx$ 0.82 \\
\hline
Régression Ridge & Faible & Élevée & Moyenne & R² $\approx$ 0.50 \\
\hline
Régression Lasso & Faible & Élevée & Moyenne & R² $\approx$ 0.48 \\
\hline
\end{tabular}
\label{tab:algorithms_comparison}
\end{table}

\subsubsection{Justification du choix : XGBoost}

XGBoost (Extreme Gradient Boosting) \cite{chen2016xgboost} a été sélectionné comme algorithme principal pour plusieurs raisons :

\textbf{Avantages théoriques :}
\begin{itemize}
    \item \textbf{Gradient boosting} : Construction séquentielle d'arbres corrigeant les erreurs précédentes
    \item \textbf{Régularisation} : Pénalisation L1 et L2 pour éviter le surapprentissage
    \item \textbf{Gestion des valeurs manquantes} : Apprentissage automatique de la direction optimale
    \item \textbf{Parallélisation} : Calcul distribué pour accélérer l'entraînement
\end{itemize}

\textbf{Avantages pratiques :}
\begin{itemize}
    \item Performance supérieure sur données tabulaires
    \item Robustesse aux outliers et aux features non normalisées
    \item Interprétabilité via feature importance et SHAP values
    \item Temps d'entraînement raisonnable (< 1 minute)
\end{itemize}

\subsubsection{Formulation mathématique de XGBoost}

\textbf{Fonction objectif :}

XGBoost minimise une fonction objectif régularisée définie comme :

\begin{equation}
\mathcal{L}(\phi) = \sum_{i=1}^{n} l(y_i, \hat{y}_i) + \sum_{k=1}^{K} \Omega(f_k)
\end{equation}

Où :
\begin{itemize}
    \item $l(y_i, \hat{y}_i)$ : Fonction de perte (MSE pour la régression)
    \item $\Omega(f_k)$ : Terme de régularisation pour l'arbre $k$
    \item $n$ : Nombre d'échantillons
    \item $K$ : Nombre d'arbres dans l'ensemble
\end{itemize}

\textbf{Terme de régularisation :}

\begin{equation}
\Omega(f) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^{T} w_j^2
\end{equation}

Où :
\begin{itemize}
    \item $T$ : Nombre de feuilles dans l'arbre
    \item $w_j$ : Score de la feuille $j$
    \item $\gamma$ : Pénalité de complexité (nombre de feuilles)
    \item $\lambda$ : Pénalité L2 sur les poids des feuilles
\end{itemize}

\textbf{Algorithme de construction d'arbre :}

À chaque itération $t$, XGBoost ajoute un nouvel arbre $f_t$ qui minimise :

\begin{equation}
\mathcal{L}^{(t)} = \sum_{i=1}^{n} l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)) + \Omega(f_t)
\end{equation}

En utilisant l'approximation de Taylor au second ordre :

\begin{equation}
\mathcal{L}^{(t)} \approx \sum_{i=1}^{n} [l(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2}h_i f_t^2(x_i)] + \Omega(f_t)
\end{equation}

Où :
\begin{itemize}
    \item $g_i = \frac{\partial l(y_i, \hat{y}_i^{(t-1)})}{\partial \hat{y}_i^{(t-1)}}$ : Gradient de premier ordre
    \item $h_i = \frac{\partial^2 l(y_i, \hat{y}_i^{(t-1)})}{\partial (\hat{y}_i^{(t-1)})^2}$ : Hessienne (gradient de second ordre)
\end{itemize}

\textbf{Gain de split optimal :}

Pour chaque split candidat, le gain est calculé comme :

\begin{equation}
Gain = \frac{1}{2}\left[\frac{G_L^2}{H_L + \lambda} + \frac{G_R^2}{H_R + \lambda} - \frac{(G_L + G_R)^2}{H_L + H_R + \lambda}\right] - \gamma
\end{equation}

Où :
\begin{itemize}
    \item $G_L = \sum_{i \in I_L} g_i$, $G_R = \sum_{i \in I_R} g_i$ : Somme des gradients gauche/droite
    \item $H_L = \sum_{i \in I_L} h_i$, $H_R = \sum_{i \in I_R} h_i$ : Somme des hessiennes gauche/droite
    \item $I_L$, $I_R$ : Ensembles d'instances dans les nœuds gauche et droite
\end{itemize}

\textbf{Poids optimal des feuilles :}

Le poids optimal d'une feuille $j$ est donné par :

\begin{equation}
w_j^* = -\frac{G_j}{H_j + \lambda}
\end{equation}

Où $G_j = \sum_{i \in I_j} g_i$ et $H_j = \sum_{i \in I_j} h_i$.

\subsubsection{Hyperparamètres optimisés}

Les hyperparamètres suivants ont été optimisés via Bayesian Optimization \cite{james2013introduction} :

\begin{table}[H]
\centering
\caption{Hyperparamètres optimisés de XGBoost}
\begin{tabular}{|p{4cm}|p{3cm}|p{3cm}|p{4cm}|}
\hline
\textbf{Hyperparamètre} & \textbf{Plage testée} & \textbf{Valeur optimale} & \textbf{Impact} \\
\hline
n\_estimators & [50, 500] & 200 & Nombre d'arbres \\
\hline
max\_depth & [3, 10] & 6 & Profondeur maximale \\
\hline
learning\_rate & [0.01, 0.3] & 0.1 & Taux d'apprentissage \\
\hline
subsample & [0.5, 1.0] & 0.8 & Échantillonnage lignes \\
\hline
colsample\_bytree & [0.5, 1.0] & 0.8 & Échantillonnage colonnes \\
\hline
gamma & [0, 5] & 0.1 & Pénalité complexité \\
\hline
lambda & [0, 10] & 1.0 & Régularisation L2 \\
\hline
alpha & [0, 10] & 0.0 & Régularisation L1 \\
\hline
\end{tabular}
\label{tab:xgboost_hyperparameters}
\end{table}

\textbf{Processus d'optimisation :}
\begin{enumerate}
    \item \textbf{Espace de recherche} : Définition des plages pour chaque hyperparamètre
    \item \textbf{Fonction objectif} : Minimisation de la MAE sur validation croisée
    \item \textbf{Optimisation bayésienne} : 100 itérations avec acquisition Expected Improvement
    \item \textbf{Validation finale} : Test sur ensemble de test indépendant
\end{enumerate}

\subsubsection{Complexité algorithmique}

\textbf{Complexité temporelle :}
\begin{itemize}
    \item \textbf{Entraînement} : $O(K \cdot d \cdot n \log n)$
    \begin{itemize}
        \item $K$ : Nombre d'arbres (200)
        \item $d$ : Nombre de features (15)
        \item $n$ : Nombre d'échantillons (14,567)
        \item $\log n$ : Tri pour trouver les meilleurs splits
    \end{itemize}
    \item \textbf{Prédiction} : $O(K \cdot \log T)$
    \begin{itemize}
        \item $K$ : Nombre d'arbres
        \item $T$ : Profondeur moyenne des arbres (6)
    \end{itemize}
\end{itemize}

\textbf{Complexité spatiale :}
\begin{itemize}
    \item \textbf{Modèle} : $O(K \cdot T)$ pour stocker les arbres
    \item \textbf{Entraînement} : $O(n \cdot d)$ pour les gradients et hessiennes
\end{itemize}

\subsubsection{Modèle d'optimisation de la planification}

Pour l'optimisation de la planification, nous utilisons une approche hybride combinant :

\begin{itemize}
    \item \textbf{Programmation par contraintes} : Modélisation des contraintes métier
    \item \textbf{Algorithmes heuristiques} : Exploration de l'espace des solutions
    \item \textbf{Optimisation multi-objectifs} : Équilibrage des critères de performance
\end{itemize}

\subsection{Ingénierie des caractéristiques avancées}

\subsubsection{Features temporelles}

\begin{itemize}
    \item \textbf{Features cycliques} : Encodage sinusoïdal des heures et jours
    \item \textbf{Lags temporels} : Temps moyen des 7 derniers jours par machine
    \item \textbf{Tendances} : Évolution de la performance sur 30 jours
\end{itemize}

\subsubsection{Features d'interaction}

\begin{itemize}
    \item \textbf{Charge machine} : Nombre d'opérations simultanées par machine
    \item \textbf{Complexité produit} : Score basé sur les dimensions et le nombre de plis
    \item \textbf{Efficacité opérateur} : Performance historique par opérateur
\end{itemize}

\subsubsection{Features de contexte}

\begin{itemize}
    \item \textbf{Saisonnalité} : Indicateurs de période (vacances, pics de production)
    \item \textbf{État machine} : Maintenance récente, âge de la machine
    \item \textbf{Priorité commande} : Délais de livraison, importance client
\end{itemize}

\subsection{Validation et sélection de modèles}

\subsubsection{Stratégie de validation}

Nous utilisons une validation croisée temporelle pour respecter la chronologie des données :

\begin{itemize}
    \item \textbf{Time Series Split} : 5 folds avec progression temporelle
    \item \textbf{Gap temporel} : 7 jours entre train et validation
    \item \textbf{Métriques} : R², MAE, RMSE, MAPE
\end{itemize}

\subsubsection{Sélection des hyperparamètres}

\begin{itemize}
    \item \textbf{Random Forest} : Grid search sur n\_estimators, max\_depth, min\_samples\_split
    \item \textbf{XGBoost} : Bayesian optimization sur learning\_rate, n\_estimators, max\_depth
    \item \textbf{Validation} : 3-fold CV temporelle pour chaque configuration
\end{itemize}

\section{Implémentation des modèles}\label{chap4:implementation}

\subsection{Modèle de prédiction du temps (Time Predictor)}

\subsubsection{Architecture du modèle}

Le modèle de prédiction utilise un pipeline de machine learning robuste :

\begin{enumerate}
    \item \textbf{Préprocessing} : Nettoyage et normalisation des données
    \item \textbf{Feature Engineering} : Création des caractéristiques dérivées
    \item \textbf{Modèle principal} : XGBoost avec hyperparamètres optimisés
    \item \textbf{Post-processing} : Validation des prédictions et gestion des valeurs aberrantes
\end{enumerate}

\subsubsection{Caractéristiques du modèle final}

\begin{itemize}
    \item \textbf{Algorithme} : XGBoost Regressor
    \item \textbf{Features} : 15 caractéristiques (dimensions, machine, contexte temporel)
    \item \textbf{Performance} : R² = 0.84, MAE = 12.3 minutes
    \item \textbf{Temps d'entraînement} : 45 secondes sur dataset complet
    \item \textbf{Temps de prédiction} : < 100ms par prédiction
\end{itemize}

\subsection{Modèle d'optimisation de la planification (Scheduler)}

\subsubsection{Formulation du problème}

Le problème d'optimisation de la planification est formulé comme un problème de programmation par contraintes :

\begin{align}
\min \quad & \sum_{i=1}^{n} \sum_{j=1}^{m} \sum_{t=1}^{T} c_{ijt} \cdot x_{ijt} \\
\text{s.t.} \quad & \sum_{j=1}^{m} \sum_{t=1}^{T} x_{ijt} = 1 \quad \forall i \in \{1,\ldots,n\} \\
& \sum_{i=1}^{n} x_{ijt} \leq 1 \quad \forall j \in \{1,\ldots,m\}, t \in \{1,\ldots,T\} \\
& x_{ijt} \in \{0,1\} \quad \forall i,j,t
\end{align}

Où :
\begin{itemize}
    \item $x_{ijt}$ : Variable binaire indiquant si l'opération $i$ est assignée à la machine $j$ au temps $t$
    \item $c_{ijt}$ : Coût d'assignation de l'opération $i$ à la machine $j$ au temps $t$
    \item $n$ : Nombre d'opérations à planifier
    \item $m$ : Nombre de machines disponibles
    \item $T$ : Horizon de planification
\end{itemize}

\subsubsection{Algorithme d'optimisation}

Nous utilisons un algorithme hybride combinant :

\begin{enumerate}
    \item \textbf{Construction initiale} : Algorithme glouton basé sur les prédictions ML
    \item \textbf{Amélioration locale} : Recherche tabou avec voisinage adaptatif
    \item \textbf{Optimisation globale} : Algorithme génétique pour l'exploration
\end{enumerate}

\subsubsection{Métriques d'optimisation}

\begin{itemize}
    \item \textbf{Temps total} : Minimisation de la durée totale de production
    \item \textbf{Équilibrage} : Répartition équitable de la charge entre machines
    \item \textbf{Priorités} : Respect des délais critiques
    \item \textbf{Efficacité} : Maximisation du taux d'utilisation des ressources
\end{itemize}

\section{Phase 5 : Évaluation (Evaluation)}\label{chap4:evaluation}

\subsection{Évaluation du modèle de prédiction}

\subsubsection{Métriques de performance}

\begin{table}[H]
\centering
\caption{Performance du modèle de prédiction}
\begin{tabular}{|p{3cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\textbf{Métrique} & \textbf{Train} & \textbf{Validation} & \textbf{Test} & \textbf{Cible} & \textbf{Statut} \\
\hline
R² & 0.89 & 0.84 & 0.82 & > 0.80 & OK \\
\hline
MAE (min) & 8.2 & 12.3 & 13.1 & < 15 & OK \\
\hline
RMSE (min) & 15.7 & 18.9 & 19.4 & < 20 & OK \\
\hline
MAPE (\%) & 18.5 & 22.1 & 23.8 & < 25 & OK \\
\hline
\end{tabular}
\label{tab:prediction_performance}
\end{table}

\subsubsection{Analyse des erreurs}

\begin{itemize}
    \item \textbf{Erreurs systématiques} : Sous-estimation de 5\% pour les opérations complexes
    \item \textbf{Valeurs aberrantes} : 3\% des prédictions avec erreur > 50\%
    \item \textbf{Biais temporel} : Performance dégradée le vendredi (-8\%)
    \item \textbf{Biais machine} : Sur-estimation pour les machines récentes (+12\%)
\end{itemize}

\subsubsection{Interprétabilité du modèle avec SHAP}

L'interprétabilité du modèle est essentielle pour la confiance des utilisateurs et la validation métier. Nous utilisons SHAP (SHapley Additive exPlanations) \cite{lundberg2017unified} pour expliquer les prédictions.

\textbf{Valeurs de Shapley :}

Les valeurs SHAP sont basées sur la théorie des jeux coopératifs. Pour une prédiction donnée, la contribution de chaque feature $i$ est calculée comme :

\begin{equation}
\phi_i = \sum_{S \subseteq F \setminus \{i\}} \frac{|S|!(|F|-|S|-1)!}{|F|!} [f_{S \cup \{i\}}(x_{S \cup \{i\}}) - f_S(x_S)]
\end{equation}

Où :
\begin{itemize}
    \item $F$ : Ensemble de toutes les features
    \item $S$ : Sous-ensemble de features ne contenant pas $i$
    \item $f_S(x_S)$ : Prédiction du modèle utilisant uniquement les features dans $S$
    \item $\phi_i$ : Contribution de la feature $i$ à la prédiction
\end{itemize}

\textbf{Propriétés des valeurs SHAP :}
\begin{itemize}
    \item \textbf{Additivité} : $\sum_{i=1}^{d} \phi_i = f(x) - E[f(X)]$
    \item \textbf{Cohérence} : Si une feature contribue plus dans tous les contextes, sa valeur SHAP est plus élevée
    \item \textbf{Symétrie} : Features interchangeables ont des valeurs SHAP identiques
    \item \textbf{Dummy} : Features sans impact ont une valeur SHAP nulle
\end{itemize}

\textbf{Feature importance globale :}

\begin{table}[H]
\centering
\caption{Importance des features (SHAP values moyennes)}
\begin{tabular}{|p{4cm}|p{2.5cm}|p{2.5cm}|p{4cm}|}
\hline
\textbf{Feature} & \textbf{SHAP moyen} & \textbf{Écart-type} & \textbf{Interprétation métier} \\
\hline
volume\_matelas & 3.8 & 2.1 & Volume = facteur principal \\
\hline
Nbr\_Plies & 2.9 & 1.8 & Plus de plis = plus de temps \\
\hline
surface\_matelas & 2.3 & 1.5 & Surface influence temps \\
\hline
temps\_moyen\_machine\_7j & 1.9 & 1.2 & Historique machine pertinent \\
\hline
score\_complexite & 1.6 & 1.0 & Complexité bien capturée \\
\hline
Longeur\_Matela & 1.4 & 0.9 & Longueur impact modéré \\
\hline
Machine (one-hot) & 1.2 & 0.8 & Différences entre machines \\
\hline
Operateur (target enc.) & 1.0 & 0.7 & Compétence opérateur \\
\hline
charge\_machine\_jour & 0.8 & 0.5 & Charge influence faible \\
\hline
jour\_semaine\_sin/cos & 0.6 & 0.4 & Effet jour limité \\
\hline
\end{tabular}
\label{tab:shap_importance}
\end{table}

\textbf{Validation métier :}

L'analyse SHAP confirme l'alignement avec l'expertise métier :
\begin{itemize}
    \item \textbf{Volume matelas} : Feature la plus importante (conforme à l'intuition)
    \item \textbf{Nombre de plis} : Deuxième facteur (validé par les experts)
    \item \textbf{Historique machine} : Capture l'état et la performance des équipements
    \item \textbf{Complexité} : Score composite bien corrélé avec le temps réel
\end{itemize}

\textbf{Exemples d'explications locales :}

Pour une prédiction spécifique (OF\_12345, temps prédit = 65 minutes) :
\begin{itemize}
    \item \textbf{Baseline} : 42.8 minutes (moyenne du dataset)
    \item \textbf{volume\_matelas = 165,000 cm³} : +15.2 minutes (volume élevé)
    \item \textbf{Nbr\_Plies = 25} : +8.5 minutes (nombre élevé)
    \item \textbf{Machine = Machine\_B} : -2.3 minutes (machine rapide)
    \item \textbf{Operateur = OP\_3} : +1.8 minutes (opérateur moins expérimenté)
    \item \textbf{Autres features} : +0.8 minutes
    \item \textbf{Total} : 42.8 + 22.2 = 65.0 minutes
\end{itemize}

Cette transparence permet aux planificateurs de comprendre et valider les prédictions.

\subsubsection{Validation croisée temporelle}

La validation croisée temporelle respecte l'ordre chronologique des données, essentiel pour les séries temporelles.

\textbf{Stratégie Time Series Split :}

\begin{enumerate}
    \item \textbf{Fold 1} : Train (Jan-Fév), Val (Mars) → R² = 0.83, MAE = 13.2 min
    \item \textbf{Fold 2} : Train (Jan-Mars), Val (Avril) → R² = 0.85, MAE = 12.1 min
    \item \textbf{Fold 3} : Train (Jan-Avril), Val (Mai) → R² = 0.84, MAE = 12.8 min
    \item \textbf{Fold 4} : Train (Jan-Mai), Val (Juin) → R² = 0.82, MAE = 13.5 min
    \item \textbf{Fold 5} : Train (Jan-Juin), Val (Juillet) → R² = 0.84, MAE = 12.6 min
\end{itemize}

\textbf{Statistiques de validation croisée :}
\begin{itemize}
    \item \textbf{R² moyen} : 0.836 ± 0.011 (très stable)
    \item \textbf{MAE moyen} : 12.84 ± 0.52 minutes
    \item \textbf{RMSE moyen} : 18.92 ± 0.68 minutes
    \item \textbf{MAPE moyen} : 22.3 ± 1.2\%
\end{itemize}

La faible variance des métriques (CV < 5\%) indique une excellente stabilité du modèle.

\subsubsection{Courbes d'apprentissage}

Les courbes d'apprentissage analysent l'évolution de la performance en fonction de la taille du dataset.

\textbf{Analyse de la convergence :}

\begin{table}[H]
\centering
\caption{Performance en fonction de la taille du dataset}
\begin{tabular}{|p{3cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\textbf{Taille dataset} & \textbf{R² Train} & \textbf{R² Val} & \textbf{Gap} & \textbf{Statut} \\
\hline
20\% (2,913) & 0.92 & 0.72 & 0.20 & Surapprentissage \\
\hline
40\% (5,827) & 0.91 & 0.78 & 0.13 & Amélioration \\
\hline
60\% (8,740) & 0.90 & 0.82 & 0.08 & Bon équilibre \\
\hline
80\% (11,654) & 0.89 & 0.84 & 0.05 & Optimal \\
\hline
100\% (14,567) & 0.89 & 0.84 & 0.05 & Convergé \\
\hline
\end{tabular}
\label{tab:learning_curves}
\end{table}

\textbf{Observations :}
\begin{itemize}
    \item \textbf{Convergence atteinte} : Performance stable à partir de 80\% des données
    \item \textbf{Pas de surapprentissage} : Gap train-validation faible (5\%)
    \item \textbf{Biais-variance équilibré} : Bon compromis atteint
    \item \textbf{Données suffisantes} : 14,567 échantillons suffisent pour la généralisation
\end{itemize}

\subsubsection{Courbes de validation}

Les courbes de validation analysent l'impact des hyperparamètres sur la performance.

\textbf{Impact de la profondeur des arbres (max\_depth) :}
\begin{itemize}
    \item \textbf{max\_depth = 3} : R² = 0.76 (sous-apprentissage)
    \item \textbf{max\_depth = 6} : R² = 0.84 (optimal)
    \item \textbf{max\_depth = 10} : R² = 0.83 (surapprentissage léger)
\end{itemize}

\textbf{Impact du nombre d'arbres (n\_estimators) :}
\begin{itemize}
    \item \textbf{n\_estimators = 50} : R² = 0.79 (insuffisant)
    \item \textbf{n\_estimators = 200} : R² = 0.84 (optimal)
    \item \textbf{n\_estimators = 500} : R² = 0.84 (pas d'amélioration, temps ×2.5)
\end{itemize}

\textbf{Impact du taux d'apprentissage (learning\_rate) :}
\begin{itemize}
    \item \textbf{learning\_rate = 0.01} : R² = 0.82 (convergence lente)
    \item \textbf{learning\_rate = 0.1} : R² = 0.84 (optimal)
    \item \textbf{learning\_rate = 0.3} : R² = 0.81 (instabilité)
\end{itemize}

\subsubsection{Matrice de comparaison des modèles}

Comparaison finale de tous les algorithmes testés :

\begin{table}[H]
\centering
\caption{Comparaison complète des modèles de régression}
\begin{tabular}{|p{3cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{2cm}|}
\hline
\textbf{Modèle} & \textbf{R²} & \textbf{MAE} & \textbf{RMSE} & \textbf{MAPE} & \textbf{Temps (s)} \\
\hline
Régression Linéaire & 0.45 & 28.3 & 35.2 & 42.1\% & 0.2 \\
\hline
Ridge & 0.48 & 27.1 & 34.5 & 40.8\% & 0.3 \\
\hline
Lasso & 0.46 & 27.8 & 35.0 & 41.5\% & 0.4 \\
\hline
Random Forest & 0.78 & 15.8 & 22.4 & 26.2\% & 12.5 \\
\hline
\textbf{XGBoost} & \textbf{0.84} & \textbf{12.3} & \textbf{18.9} & \textbf{22.1\%} & \textbf{45.0} \\
\hline
Gradient Boosting & 0.81 & 13.9 & 20.8 & 24.3\% & 78.2 \\
\hline
\end{tabular}
\label{tab:model_comparison_complete}
\end{table}

\textbf{Justification du choix final :}
\begin{itemize}
    \item \textbf{XGBoost} offre le meilleur compromis performance/temps
    \item Amélioration de +87\% sur R² vs régression linéaire
    \item Temps d'entraînement acceptable (< 1 minute)
    \item Robustesse validée par validation croisée
\end{itemize}

\subsubsection{Tests de significativité statistique}

Validation statistique de la supériorité de XGBoost.

\textbf{Test de Wilcoxon signé-rank :}

Comparaison XGBoost vs Random Forest sur les 5 folds de validation croisée :
\begin{itemize}
    \item \textbf{Hypothèse nulle} : Pas de différence significative entre les modèles
    \item \textbf{Statistique W} : 15 (somme des rangs positifs)
    \item \textbf{p-value} : 0.031 (< 0.05)
    \item \textbf{Conclusion} : XGBoost significativement meilleur (α = 0.05)
\end{itemize}

\textbf{Intervalle de confiance à 95\% :}
\begin{itemize}
    \item \textbf{R²} : [0.825, 0.847] (XGBoost) vs [0.765, 0.795] (Random Forest)
    \item \textbf{MAE} : [12.32, 13.36] min (XGBoost) vs [15.12, 16.48] min (Random Forest)
    \item \textbf{Pas de chevauchement} : Différence statistiquement significative
\end{itemize}

\subsection{Évaluation du modèle d'optimisation}

\subsubsection{Métriques d'optimisation}

\begin{table}[H]
\centering
\caption{Performance du modèle d'optimisation}
\begin{tabular}{|p{3cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\textbf{Métrique} & \textbf{Baseline} & \textbf{Optimisé} & \textbf{Amélioration} & \textbf{Cible} & \textbf{Statut} \\
\hline
Temps total (h) & 8.5 & 6.8 & -20\% & -15\% & OK \\
\hline
Équilibrage charge & 0.65 & 0.89 & +37\% & +30\% & OK \\
\hline
Respect délais (\%) & 78 & 94 & +16\% & +15\% & OK \\
\hline
Utilisation machines (\%) & 72 & 87 & +15\% & +15\% & OK \\
\hline
\end{tabular}
\label{tab:optimization_performance}
\end{table}

\subsubsection{Analyse de robustesse}

\begin{itemize}
    \item \textbf{Variabilité} : Écart-type des solutions < 5\%
    \item \textbf{Convergence} : 95\% des exécutions convergent en < 30s
    \item \textbf{Scalabilité} : Performance maintenue jusqu'à 100 opérations
    \item \textbf{Résistance} : Stabilité face aux perturbations (+/- 20\% temps)
\end{itemize}

\section{Intégration et déploiement}\label{chap4:integration}

\subsection{Architecture du système}

\begin{figure}[H]
\centering
% \includegraphics[width=0.9\textwidth]{images/ml_system_architecture.png}
\caption{Architecture du système ML intégré}
\label{fig:ml_architecture}
\end{figure}

\subsection{Pipeline de production}

\subsubsection{Entraînement automatique}

\begin{itemize}
    \item \textbf{Fréquence} : Entraînement quotidien à 6h00
    \item \textbf{Déclenchement} : Nouveau modèle si dérive détectée
    \item \textbf{Validation} : Tests automatiques avant déploiement
    \item \textbf{Rollback} : Retour automatique en cas de dégradation
\end{itemize}

\subsubsection{Serving en production}

\begin{itemize}
    \item \textbf{API REST} : Endpoints FastAPI pour prédictions
    \item \textbf{Latence} : < 200ms pour prédictions individuelles
    \item \textbf{Débit} : 1000 prédictions/minute
    \item \textbf{Monitoring} : Surveillance continue des performances
\end{itemize}

\subsection{Gestion des modèles}

\subsubsection{Versioning}

\begin{itemize}
    \item \textbf{MLflow} : Tracking des expériences et versioning
    \item \textbf{Registry} : Stockage centralisé des modèles
    \item \textbf{Métadonnées} : Traçabilité complète des modèles
    \item \textbf{Comparaison} : Outils de comparaison des versions
\end{itemize}

\subsubsection{Monitoring}

\begin{itemize}
    \item \textbf{Dérive des données} : Détection automatique des changements
    \item \textbf{Dérive du modèle} : Surveillance de la performance
    \item \textbf{Alertes} : Notifications en cas de problème
    \item \textbf{Dashboards} : Visualisation des métriques en temps réel
\end{itemize}

\section{Validation métier}\label{chap4:business_validation}

\subsection{Tests avec les utilisateurs}

\subsubsection{Protocole de test}

\begin{enumerate}
    \item \textbf{Phase 1} : Tests en environnement de développement (2 semaines)
    \item \textbf{Phase 2} : Tests avec un groupe pilote (4 semaines)
    \item \textbf{Phase 3} : Déploiement progressif sur toutes les machines (6 semaines)
\end{enumerate}

\subsubsection{Métriques de satisfaction}

\begin{itemize}
    \item \textbf{Utilisabilité} : Score SUS > 70
    \item \textbf{Précision} : Satisfaction utilisateurs > 4/5
    \item \textbf{Efficacité} : Réduction du temps de planification > 50\%
    \item \textbf{Adoption} : Taux d'utilisation > 90\%
\end{itemize}

\subsection{Impact métier mesuré}

\subsubsection{KPIs opérationnels}

\begin{table}[H]
\centering
\caption{Impact métier mesuré}
\begin{tabular}{|p{3cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\textbf{KPI} & \textbf{Avant} & \textbf{Après} & \textbf{Amélioration} & \textbf{Cible} & \textbf{Statut} \\
\hline
Temps planification (h) & 2.5 & 1.0 & -60\% & -60\% & OK \\
\hline
Précision estimations (\%) & 65 & 84 & +19\% & +15\% & OK \\
\hline
Utilisation machines (\%) & 72 & 87 & +15\% & +15\% & OK \\
\hline
Retards livraison (\%) & 12 & 8 & -33\% & -25\% & OK \\
\hline
Satisfaction utilisateurs & 3.2 & 4.3 & +34\% & +25\% & OK \\
\hline
\end{tabular}
\label{tab:business_impact}
\end{table}

\subsubsection{ROI du projet}

\begin{itemize}
    \item \textbf{Investissement} : 45,000 TND (développement + déploiement)
    \item \textbf{Gains annuels} : 78,000 TND (productivité + qualité)
    \item \textbf{ROI} : 73\% sur 12 mois
    \item \textbf{Période de retour} : 7 mois
\end{itemize}

\section{Synthèse et perspectives}\label{chap4:synthesis}

\subsection{Bilan de la modélisation}

Les phases de modélisation et d'évaluation ont permis d'atteindre les objectifs fixés :

\begin{itemize}
    \item \textbf{Modèle de prédiction} : Performance supérieure aux attentes (R² = 0.82 vs 0.80 cible)
    \item \textbf{Modèle d'optimisation} : Amélioration significative de l'efficacité opérationnelle
    \item \textbf{Intégration} : Système robuste et scalable en production
    \item \textbf{Validation métier} : Impact positif mesuré sur tous les KPIs
\end{itemize}

\subsection{Limitations identifiées}

\begin{itemize}
    \item \textbf{Données} : Qualité variable selon les périodes et machines
    \item \textbf{Complexité} : Modèles sensibles aux changements de processus
    \item \textbf{Maintenance} : Nécessité d'un suivi continu des performances
    \item \textbf{Évolutivité} : Adaptation requise pour de nouveaux types de produits
\end{itemize}

\subsection{Améliorations futures}

\begin{itemize}
    \item \textbf{Modèles avancés} : Intégration de techniques de deep learning
    \item \textbf{Données enrichies} : Ajout de capteurs IoT pour plus de précision
    \item \textbf{Optimisation continue} : Apprentissage en ligne des modèles
    \item \textbf{Prédiction multi-horizons} : Planification à moyen et long terme
\end{itemize}

Le chapitre suivant présentera la méthodologie agile de déploiement et la roadmap de mise en œuvre du système d'intelligence artificielle.
